# -*- coding: utf-8 -*-
"""squeezenet_mnist_preprocessamento.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GipR0j2nN4YAUio7UQhGD0E3K7xf4cqp
"""

#https://github.com/sandgate-dev/coding-practice/blob/master/coding/ml-dl/tensorfow/untitled-2/implementation-of-a-cnn-fire-module-for-squeezenet.md

#referencia do codigo:
#https://stephan-osterburg.gitbook.io/coding/coding/ml-dl/tensorfow/untitled-2/train-and-evaluate-squeezenet-on-cifar10-dataset

#importando bibliotecas
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

#carregando dados necessários em variáveis pra facilitar o uso
datasets = tf.keras.datasets
layers = tf.keras.layers
models = tf.keras.models
losses = tf.keras.losses
optimizers = tf.keras.optimizers
metrics = tf.keras.metrics
preprocessing_image = tf.keras.preprocessing.image
utils = tf.keras.utils
callbacks = tf.keras.callbacks

#carregando o MNIST em variáveis de treino e de teste
#essas variáveis contém vetores de dados
#dados baixados direto do tensowflow
(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()

# Sample de imagens do MNIST - printa uma imagem do MNIST
# plt.figure()
# plt.imshow(x_train[59000,:,:])
# plt.show()

#expande as dimensões do dataset
#essas funções são utilizadas para que se encaixem na entrada da squeezenet
#dados de treino
x_train = np.expand_dims(x_train, axis=-1)
print(x_train.shape)

#expande as dimensões do dataset
#essas funções são utilizadas para que se encaixem na entrada da squeezenet
#dados de teste
x_test = np.expand_dims(x_test, axis=-1)
print(x_test.shape)

#gera batches de imagens do MNIST com o aumento de dados em tempo real
#apenas dados de treino
train_datagen = preprocessing_image.ImageDataGenerator(
      #fator para reescala das imagens. Multiplica as imagens pelo fator informado. 
      #Nesse caso transforma todas as imagens em um fator de 0 a 255
      #nomalização de dados
      rescale=1./255,
      #intensidade de cisalhamento (ângulo de cisalhamento no sentido anti-horário em graus)
      shear_range=0.1,
      #alcance para zoom aleatório
      zoom_range=0.1,
      #rotaciona as entradas na horizontal de forma aleatória
      horizontal_flip=True)

#gera batches de imagens do MNIST com o aumento de dados em tempo real
#realiza o reescalamento das imagens
#apenas dados de teste
test_datagen = preprocessing_image.ImageDataGenerator(rescale=1./255)

#transforma vetores de classes (nomes de classes que são inteiros) para uma
#matriz de classes binária
#One Hot Encoding
y_train = utils.to_categorical(y_train, num_classes=10)
y_test = utils.to_categorical(y_test, num_classes=10)

#criando o generator de treino e teste
train_generator = train_datagen.flow(x=x_train, y=y_train, batch_size=32, shuffle=True)
test_generator = train_datagen.flow(x=x_test, y=y_test, batch_size=32, shuffle=True)

#As próximas funções irão recriar o modelo da squeezenet proposta do Iandola et. al
#esse modelo foi criado em https://stephan-osterburg.gitbook.io/coding/coding/ml-dl/tensorfow/untitled-2/train-and-evaluate-squeezenet-on-cifar10-dataset

#SQUEEZENET MODEL

#fire module
#módulo que expande e reduz as camadas da rede, esse é o diferencial da squeezenet e o 
#que faz ela ser uma rede pequena
def fire_module(x, fire_id, squeeze=16, expand=64):
    sq1x1 = "squeeze1x1"
    exp1x1 = "expand1x1"
    exp3x3 = "expand3x3"
    relu = "relu_"
    s_id = 'fire' + str(fire_id) + '/'

    channel_axis = 3
    # Squeeze part of fire module with 1*1 convolutions followed by Relu
    #compressão de camadas com convoluções 1x1, seguida de aplicações da ReLU
    x = layers.Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)
    x = layers.Activation('relu', name=s_id + relu + sq1x1)(x)
    
    # Expand part has two portions, left 1*1 convolutions and is called expand1x1
    #expansão de camadas com convoluções 1x1 
    #essa parte recebe a camada processada comprimida
    left = layers.Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)
    left = layers.Activation('relu', name=s_id + relu + exp1x1)(left)

    # Right part uses 3 * 3 convolutions and is called expand3x3
    #expansão de camadas com convoluções 3x3
    #essa parte recebe a camada processada comprimida
    right = layers.Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)
    right = layers.Activation('relu', name=s_id + relu + exp3x3)(right)

    #concatenação da camada processada pela direita e pela esquerda
    x = layers.concatenate([left, right], axis=channel_axis, name=s_id + 'concat')

    #retorna a camada com a compressão e duas expansões
    return x

#modelo da squeezenet é feito na função SqueezeNet
def SqueezeNet(input_shape=(28,28,1), classes=10):

    img_input = layers.Input(shape=input_shape)

    #primeira camada convolucional
    x = layers.Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)
    x = layers.Activation('relu', name='relu_conv1')(x)
    #x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)

    #utilização do fire module
    x = fire_module(x, fire_id=2, squeeze=16, expand=64)
    x = fire_module(x, fire_id=3, squeeze=16, expand=64)
    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)

    x = fire_module(x, fire_id=4, squeeze=32, expand=128)
    x = fire_module(x, fire_id=5, squeeze=32, expand=128)
    x = layers.Dropout(0.5, name='drop9')(x)

    #segunda camada convolucional
    x = layers.Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)
    x = layers.Activation('relu', name='relu_conv10')(x)
    x = layers.GlobalAveragePooling2D()(x)
    out = layers.Activation('softmax', name='loss')(x)

    #criando o modelo da squeezenet
    model = models.Model(img_input, out, name='squeezenet')

    #retornando o modelo
    return model

#função para compilar o modelo
def compile_model(model):

    #erro
    loss = losses.categorical_crossentropy

    #otimizador
    optimizer = optimizers.RMSprop(learning_rate=0.0001)

    #métrica utilizada
    metric = [metrics.categorical_accuracy, metrics.top_k_categorical_accuracy]

    #compile model with loss, optimizer, and evaluation metrics
    #compilação do modelo
    model.compile(optimizer, loss, metric)

    #retornando o modelo compilado
    return model

#criando o modelo e o compilando (chamando as funções para tal)
model = SqueezeNet()
model = compile_model(model)

#treinando o modelo
epoch = 45      #quantidade de épocas
history = model.fit_generator(
    train_generator,
    steps_per_epoch=400,
    epochs=epoch,
    validation_data=test_generator,
    validation_steps=200)

# #função para plotar os gráficos de erro e acurácia do modelo
# #faz uma relação entre o que foi treinado e o teste do modelo com os samples do mnist
# def plot_accuracy_and_loss(history):
#     plt.figure(1, figsize= (15, 10))

#     # plot train and test accuracy
#     plt.subplot(221)
#     plt.plot(history.history['categorical_accuracy'])
#     plt.plot(history.history['val_categorical_accuracy'])
#     plt.title('SqueezeNet accuracy')
#     plt.ylabel('accuracy')
#     plt.xlabel('epoch')
#     plt.legend(['train', 'test'], loc='upper left')

#     # plot train and test loss
#     plt.subplot(222)
#     plt.plot(history.history['loss'])
#     plt.plot(history.history['val_loss'])
#     plt.title('SqueezeNet loss')
#     plt.ylabel('loss')
#     plt.xlabel('epoch')
#     plt.legend(['train', 'test'], loc='upper right')

#     plt.show()

# #plota o gráfico chamando a função
# plot_accuracy_and_loss(history)

#cria pasta para salvar o modelo
#!mkdir -p MyDrive/saved_model

#armazena o tempo total da época em str
total_epoch = str(epoch)

# #salva o modelo em formado .json
# model_json = model.to_json()
# open('saved_model/squeeze_net_model_epochs_' + total_epoch + '.json', 'w').write(model_json)

# #salva o modelo treinado com seus respectivos pesos
# model.save_weights('saved_model/image_classifier_squeeze_net_epochs_' + total_epoch + '.h5', overwrite=True)

#avalia o modelo e printa a acurácia
acc = model.evaluate(x_test, y_test, verbose=1)
print(acc)

#salva o modelo no formato pb
model.save('content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Squeezenet/model_squeeze/modelo'+ total_epoch)

#salva o modelo no formado .h5
model.save('saved_model/model_squeeze.h5')

#converte o modelo para o formato .tflite
converter = tf.lite.TFLiteConverter.from_saved_model('content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Squeezenet/model_squeeze/modelo'+ total_epoch) # path to the SavedModel directory

#converter.experimental_new_converter = True
tflite_model = converter.convert()

#salva o modelo em memória.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

#https://stackoverflow.com/questions/41488279/neural-network-always-predicts-the-same-class
import os
import matplotlib.pyplot as plt
import cv2
from datetime import datetime


def invert_black_and_white(img):
    matriz = 255 * np.ones(img.shape)
    img_inverted = matriz - img
    return img_inverted

predicoes = []
def predict_test():
  pasta = r'/content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Algoritmos Rafael/imagens-processadas/03'

  for pasta in range(8):
      pasta_number = str(pasta)
      for arquivo in range(8):
        imagem_number = str(arquivo)
        path = r'/content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Algoritmos Rafael/imagens-processadas/0' + pasta_number + '/0'+ imagem_number + '.jpg'
        print(path)

        imagem = cv2.imread(path,0)
        #print(type(imagem))
        # plt.imshow(imagem)
        # plt.show()
        print(imagem.shape)
        expand_image_inicio = np.expand_dims(imagem, axis=0)
        expand_image_fim = np.expand_dims(expand_image_inicio, axis=-1)
        normaliza = expand_image_fim/.255
        print(normaliza.shape)
        #im_invert = invert_black_and_white(normaliza)
        predicao = model.predict(normaliza)
        print(predicao)
        predicao_index = np.argmax(predicao)

        #print(predicao_index)
        
        predicoes.append("Number: " + pasta_number)
        predicoes.append("Epochs: " + total_epoch)
        predicoes.append("Prediction result: ")
        predicoes.append(predicao_index)

# dt = datetime.now()
# data = str(dt)
# with open(r'/content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Squeezenet/log_epochs_'+total_epoch+'_'+data+'.txt', 'a') as log:
#     log.writelines(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))
#     log.writelines(str(predicoes))

# Importar imagem
def import_img(path, digito, num_img):
    img_path = path + f'{digito:0>2}' + '/' + f'{num_img:0>2}' + '.jpg'
    import cv2
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if type(img) == type(None):
        raise ValueError(f'O arquivo não existe.')
    return img

# Corte de área de interesse
def roi(img):
    x = img.shape[1] // 4
    y = img.shape[0] // 4
    w = x * 2
    h = y * 2
    roi = img[y:y+h, x:x+w]
    return roi

# FFT
def fft(img, keep_fraction_value):
    from scipy import fftpack
    im_fft = fftpack.fft2(img)
    im_fft2 = im_fft.copy()
    r, c = im_fft2.shape
    keep_fraction = keep_fraction_value
    im_fft2[int(r*keep_fraction):int(r*(1-keep_fraction))] = 0
    im_fft2[:, int(c*keep_fraction):int(c*(1-keep_fraction))] = 0
    im_new = fftpack.ifft2(im_fft2).real
    return im_new

# Encontrando o número na imagem e recortando
def cut_digit_region(img, margin=40):
    points = np.argwhere(img == 0)
    points = np.fliplr(points)
    x, y, w, h = cv2.boundingRect(points)
    
    if w > h:
        y = y - ((w - h) // 2)
        h = w
    else:
        x = x - ((h - w) // 2)
        w = h

    x, y, w, h = x - margin, y - margin, w + (margin * 2), h + (margin * 2)

    if x < 0:
        x = 0
    if y < 0:
        y = 0
    if w > img.shape[1]:
        x = img.shape[1] - w
    if w > img.shape[0]:
        y = img.shape[0] - h
        
    if x < 0:
        x = 0
    if y < 0:
        y = 0
        
    img_cropped = img[y:y+h, x:x+w]
    return img_cropped

# Invertendo valores de img_cropped (preto vira branco e branco vira preto)
def invert_black_and_white(img):
    matriz = 255 * np.ones(img.shape)
    img_inverted = matriz - img
    return img_inverted

# Teste da função de processamento gaussian filter
from tensorflow import keras
def processar_2(img):
    # Área de interesse da imagem bruta
    img_roi = roi(img)

    # Filtro gaussiano
    img_gaussian_filter = cv2.GaussianBlur(img_roi, (13, 13), 0)

    # Aplicando limiar
    img_thresholded = cv2.adaptiveThreshold(img_gaussian_filter, 255,\
                                            cv2.ADAPTIVE_THRESH_MEAN_C,\
                                            cv2.THRESH_BINARY, 151, 13)
    
    # Recortando um quadrado em volta do número
    cropped_digit_image = cut_digit_region(img_thresholded)

    # Invertendo valores de img_cropped (preto vira branco e branco vira preto)
    img_thresholded_inverted = invert_black_and_white(cropped_digit_image)

    # Redimensionando a imagem e normalizando
    array_img = keras.preprocessing.image.img_to_array(img_thresholded_inverted)
    img_resized = tf.image.resize(array_img, [28, 28], antialias=True)
    img_reshaped = tf.reshape(img_resized, [28, 28])
    img_normalized = tf.keras.utils.normalize(img_reshaped, axis=-1)
    img_np_array = np.array(img_normalized)
    return img_np_array

# Expandir dimensões da imagem
def expand_img_dims(img):
    img_expanded = np.expand_dims(img, axis=0)
    img_expanded2 = np.expand_dims(img_expanded, axis=img_expanded.ndim)
    return img_expanded2

# Plotar gráfico de predições
def plot_value_array(predictions_array, true_label):
    plt.grid(False)
    plt.xticks(range(10))
    plt.yticks([])
    thisplot = plt.bar(range(10), predictions_array, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array)
    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')

# Plotar imagem
def plot_img(img, label):
    plt.imshow(img, plt.cm.binary)
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(label)

# Processar uma única imagem e plotar gráfico de predições
def predict_img(dataset_path, digito, num_img, nn):
    # Importa a imagem
    img = import_img(dataset_path, digito, num_img)

    # Pre-processamento da imagem
    img_processed = processar_2(img)

    # Expande as dimensões da imagem
    img_expanded = expand_img_dims(img_processed)

    # Predições da rede
    predicoes = nn.predict(img_expanded)
    index_predicoes = np.argmax(predicoes)

    # Plotando imagem e o gráfico de predições do dígito
    plt.figure(figsize=(6, 3))
    plt.xticks([])
    plt.yticks([])
    plt.subplot(1, 2, 1)
    plot_img(img_processed, f'{index_predicoes} | {predicoes[0][index_predicoes] * 100:.0f}%')
    plt.subplot(1, 2, 2)
    plot_value_array(predicoes[0], digito)
    plt.show()

# # Testando novas funções
# dataset_path = '/content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Algoritmos Rafael/meu-dataset/'

# digitos = 10
# qtd_img = 8

# plt.figure(figsize=(digitos * 2, qtd_img))
# plt.xticks([])
# plt.yticks([])
# cont_img = 0
# # for digito in range(digitos):
# #     for num_img in range(qtd_img):
# #         num_plot = qtd_img * digito + num_img + 1
# #         plt.subplot(digitos, qtd_img, num_plot)
# #         predict_img(dataset_path, digito, num_img, model)
# # plt.show()

# Teste com função de processamento com Gaussian Filter
dataset_path = '/content/drive/MyDrive/Sistema-Reconhecimento-Caracteres-Kamilla/Algoritmos Colab/Algoritmos Rafael/meu-dataset/'

digito = 2
num_img = 2

img = import_img(dataset_path, digito, num_img)
img_processed = processar_2(img)
img_expanded = np.expand_dims(img_processed, axis=0)
img_expanded2 = np.expand_dims(img_expanded, axis=img_expanded.ndim)

predicao = model.predict(img_expanded2)
predicao_index = np.argmax(predicao)

# ------------------------

plt.figure(figsize=(8,4))

plt.subplot(1, 2, 1)
plt.imshow(img_processed, plt.cm.binary)
plt.xlabel(f'{predicao_index} | {predicao[0][predicao_index] * 100:.0f}%')
plt.xticks([])
plt.yticks([])

plt.subplot(1, 2, 2)
plot_value_array(predicao[0], digito)

plt.show()

plt.figure(figsize=(12, 16))
qtd_digitos = 10
qtd_img = 8
for digito in range(qtd_digitos):
    for numImg in range(qtd_img):
        img = import_img(dataset_path, digito, numImg)
        img_processed = processar_2(img)
        img_expanded = np.expand_dims(img_processed, axis=0)
        img_expanded2 = np.expand_dims(img_expanded, axis=img_expanded.ndim)

        predicao = model.predict(img_expanded2)
        predicao_index = np.argmax(predicao)

        num_plot = qtd_img * digito + numImg + 1
        plt.subplot(10, 8, num_plot)
        plt.imshow(img_processed, plt.cm.binary)
        plt.xlabel(predicao_index)
        plt.xticks([])
        plt.yticks([])
plt.show()